# <img src="docs/figures/icon.svg#gh-light-mode-only" media="(prefers-color-scheme: light)" width=20><img src="docs/figures/icon.svg#gh-dark-mode-only" media="(prefers-color-scheme: dark)" width=20> FlowForge: Container Orchestration Engine

**FlowForge** (formerly TwinGraph) is a cutting-edge container orchestration engine designed for building and managing GenAI workflows at scale. It combines visual workflow design with powerful multi-language execution capabilities, enabling seamless orchestration across cloud and local infrastructure.

## üöÄ Key Features

### Visual Workflow Designer
- **Drag-and-drop interface** for building complex workflows
- **Real-time graph visualization** with live execution monitoring
- **Node-based architecture** with pre-built components
- **Interactive debugging** with node property inspection

### Multi-Language Support
- Write components in **Python**, **JavaScript**, **TypeScript**, **Bash**, **C++**, or **Rust**
- **Monaco Editor** integration for in-browser code editing
- **Syntax highlighting** and IntelliSense support
- **Hot-reload** capabilities for rapid development

### Container-First Architecture
- **Platform-agnostic execution** across Docker, Kubernetes, AWS Lambda, and AWS Batch
- **Automatic container management** and resource allocation
- **Built-in retry mechanisms** with exponential backoff
- **Distributed execution** using Celery for massive scale

### GenAI & ML Ready
- **LLM integration components** for GPT, Claude, and open models
- **Vector database support** for embeddings and similarity search
- **RAG (Retrieval-Augmented Generation)** pipeline templates
- **Multi-agent orchestration** primitives

### Enterprise Features
- **Comprehensive logging** with structured JSON output
- **Performance monitoring** and metrics collection
- **Graph database backend** (TinkerGraph/Neptune) for full auditability
- **Git integration** for version control and reproducibility

## üéØ Use Cases

- **GenAI Applications**: Build sophisticated AI pipelines with LLMs, embeddings, and vector search
- **Data Processing**: ETL workflows with parallel processing and fault tolerance
- **ML Operations**: Model training, evaluation, and deployment pipelines
- **Scientific Computing**: Simulation and optimization workflows
- **DevOps Automation**: CI/CD pipelines with multi-platform deployment

## üèóÔ∏è Architecture

FlowForge uses a modern, modular architecture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Web UI (React + TypeScript)         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ         FastAPI Backend + WebSocket          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ     Orchestration Engine (Python Core)       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Execution Platforms (Docker/K8s/Lambda)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Graph DB (TinkerGraph/Neptune) + Redis    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites
- Docker and Docker Compose
- Python 3.8+ with Poetry
- Node.js 18+ and npm
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/aws-samples/twingraph.git
   cd twingraph
   ```

2. **Quick Install (Linux)**
   ```bash
   make install
   make docker_containers_poetry
   ```

3. **Start FlowForge**
   ```bash
   # Start all services including the new UI
   sh start_flowforge.sh
   ```

4. **Access the platform**
   - üé® **Web UI**: http://localhost:4000
   - üì° **API**: http://localhost:8000
   - üìö **API Docs**: http://localhost:8000/docs
   - üîç **Graph Visualizer**: http://localhost:3000

## üíª Creating Your First Workflow

### Visual Method (Recommended)

1. Open the Web UI at http://localhost:4000
2. Drag components from the sidebar onto the canvas
3. Connect components by dragging between ports
4. Double-click components to edit their code
5. Click "Run" to execute the workflow
6. View real-time execution in the graph visualization

### Code Method

Create a simple workflow using decorators:

```python
from twingraph import component, pipeline
from typing import NamedTuple

@component()
def load_data(source: str) -> NamedTuple:
    """Load data from source"""
    Output = namedtuple('Output', ['data'])
    # Your data loading logic here
    return Output(data=[1, 2, 3, 4, 5])

@component(platform='docker', docker_image='python:3.9')
def process_data(data: list) -> NamedTuple:
    """Process data in Docker container"""
    Output = namedtuple('Output', ['result'])
    result = sum(data) / len(data)
    return Output(result=result)

@pipeline()
def analytics_pipeline():
    # Load data
    raw_data = load_data('database')
    
    # Process in Docker
    result = process_data(
        raw_data['outputs']['data'],
        parent_hash=raw_data['hash']
    )
    
    return result

# Execute pipeline
analytics_pipeline()
```

## üß© Component Library

### GenAI Components
- **LLM Prompt**: Interface with language models
- **Text Embedding**: Generate vector embeddings
- **Vector Search**: Query vector databases
- **Chain-of-Thought**: Multi-step reasoning
- **Agent Executor**: Run autonomous agents

### Data Components
- **File Reader**: Load various file formats
- **Database Query**: Connect to SQL/NoSQL databases
- **API Connector**: RESTful API integration
- **Stream Processor**: Real-time data processing

### Compute Components
- **Python Script**: Custom Python execution
- **Bash Command**: Shell script execution
- **Container Runner**: Docker-based processing
- **Parallel Map**: Distributed computation

### Control Flow
- **Conditional**: If-then-else branching
- **Loop**: Iteration over data
- **Parallel**: Concurrent execution
- **Error Handler**: Exception management

## üîß Platform Configuration

### Kubernetes Deployment
```python
@component(
    platform='kubernetes',
    docker_image='myregistry/myimage:latest',
    config={
        'namespace': 'flowforge',
        'resources': {
            'cpu': '2000m',
            'memory': '4Gi'
        }
    }
)
def k8s_component(data: dict) -> NamedTuple:
    # Runs on Kubernetes
    pass
```

### AWS Lambda Integration
```python
@component(
    platform='lambda',
    config={
        'function_name': 'my-processor',
        'timeout': 900,
        'memory_size': 3008
    }
)
def serverless_component(event: dict) -> NamedTuple:
    # Runs on AWS Lambda
    pass
```

## üìä Monitoring & Debugging

### Real-time Graph Visualization
- View execution flow in real-time
- Color-coded nodes by status and platform
- Click nodes to inspect properties
- Auto-refresh during execution

### Structured Logging
```python
from twingraph.core.logging import get_logger

logger = get_logger(__name__)
logger.log_execution(
    component='my_component',
    execution_id='abc123',
    status='success',
    duration=1.23
)
```

### Performance Metrics
- Execution time tracking
- Resource utilization monitoring
- Success/failure rates
- Platform-specific metrics

## üß™ Testing

Run the comprehensive test suite:

```bash
# All tests with coverage
python run_tests.py --verbose --coverage

# Specific test suites
python run_tests.py --unit
python run_tests.py --integration
python run_tests.py --benchmarks
```

## üö¢ Deployment

### Docker Compose (Development)
```bash
docker compose up -d
```

### Kubernetes (Production)
```bash
kubectl apply -f deploy/kubernetes/
```

### AWS EKS
See `examples/orchestration_demos/demo_5_celery_K8s/` for EKS deployment.

## üìö Examples

Explore our comprehensive examples:

| Example | Description |
|---------|-------------|
| [GenAI RAG Pipeline](examples/orchestration_demos/demo_11_genai_workflow) | Build a complete RAG system with LLMs |
| [Graph Tracing](examples/orchestration_demos/demo_1_graph_tracing) | Visualize workflow execution |
| [Multi-Platform](examples/orchestration_demos/demo_8_docker_K8s_lambda_batch) | Run across different platforms |
| [Distributed Processing](examples/orchestration_demos/demo_4_celery_backend) | Scale with Celery |

## üîå API Reference

### REST Endpoints
- `GET /api/workflows` - List workflows
- `POST /api/workflows/{id}` - Save workflow
- `POST /api/executions` - Execute workflow
- `GET /api/graph/execution/{id}` - Get execution graph

### WebSocket Events
- `execution:{id}` - Real-time execution updates
- `node:{id}:status` - Node status changes

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## üìÑ License

[MIT-0](LICENSE)

## üôè Credits

FlowForge is built on the foundation of TwinGraph, originally developed by the Autonomous Computing Team at AWS. Special thanks to:
- Vidyasagar Ananthan and Satheesh Maheswaran (Lead Development)
- Cheryl Abundo (Amazon EKS Blueprints)
- David Sauerwein (Applications)
- Ross Pivovar (Testing)
- Adam Rasheed (Leadership)
- Alex Iankoulski (Docker expertise)

## üîó Resources

- **Documentation**: [Coming Soon]
- **Discord Community**: [Join Us]
- **Blog**: [flowforge.dev/blog]
- **YouTube Tutorials**: [FlowForge Channel]

---

<p align="center">
  <b>FlowForge</b> - Forge Your Flows, Scale Your Ideas üöÄ
</p>